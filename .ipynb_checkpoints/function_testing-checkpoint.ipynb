{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from image_funcs import *\n",
    "import skimage\n",
    "import peakutils\n",
    "import cv2\n",
    "from tqdm import tqdm  \n",
    "import imageio\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from pystackreg import StackReg\n",
    "from skimage.util import img_as_uint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FOVs(directory, channel, padding):\n",
    "    channel = channel\n",
    "    z = 0\n",
    "    FOV = \"xy{}\".format(str(z).zfill(padding))\n",
    "    while len(images := glob.glob(directory + \"{}**{}.tif\".format(FOV,channel))) > 0:\n",
    "        FOV = \"xy{}\".format(str(z).zfill(padding))\n",
    "        z += 1\n",
    "    num_FOVs = z-1\n",
    "    \n",
    "    FOVs = []\n",
    "    for x in range(num_FOVs):\n",
    "        FOVs.append(\"xy{}\".format(str(x).zfill(padding)))\n",
    "    \n",
    "    return FOVs\n",
    "\n",
    "def get_image_list(directory,FOV, channel):\n",
    "    images =  glob.glob(directory + \"{}**{}.tif\".format(FOV,channel)) \n",
    "    images.sort()\n",
    "    return images\n",
    "\n",
    "def drift_correct_images(image_list, bit_size = np.uint16):\n",
    "    ref = io.imread(image_list[0])\n",
    "    drift_corrected_images = Parallel(n_jobs=-1)(delayed(correct_drift)(ref, io.imread(image_list[i])) for i in tqdm(range(len(image_list))))\n",
    "    all_images = [drift_corrected_images[x][0].astype(bit_size) for x in range(len(drift_corrected_images))]\n",
    "    trans_matrices = [drift_corrected_images[x][1] for x in range(len(drift_corrected_images))]\n",
    "    return all_images, trans_matrices\n",
    "\n",
    "\n",
    "def image_splitter(images):\n",
    "    top_half_images = []\n",
    "    bottom_half_images = []\n",
    "    for i in range(len(images)):\n",
    "        top_half_images.append(get_img_half(images[i],\"top\"))\n",
    "        bottom_half_images.append(get_img_half(images[i],\"bottom\"))\n",
    "    return top_half_images, bottom_half_images\n",
    "\n",
    "def make_diagnostic_directories(output_directory):\n",
    "\n",
    "    diag_directories = [\n",
    "    \"diagnostics\",\n",
    "    \"diagnostics/rotations\",\n",
    "    \"diagnostics/top_split\",\n",
    "    \"diagnostics/bottom_split\",\n",
    "    \"diagnostics/trench_finding\"]\n",
    "\n",
    "    for direc in diag_directories:\n",
    "        try:\n",
    "            os.mkdir(output_directory + direc)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "def save_image(image_directory, frame):\n",
    "    cv2.imwrite(image_directory, frame, [cv2.IMWRITE_TIFF_COMPRESSION, 1])\n",
    "\n",
    "def register_transform_save_FOV(directory, FOV, phase_channel, fluor_channels):\n",
    "    img_directories = get_image_list(directory,FOV, phase_channel)\n",
    "    images, trans_matrices = drift_correct_images(img_directories)\n",
    "    Parallel(n_jobs=-1)(delayed(save_image)(directory, image) for directory, image in tqdm(zip(img_directories, images), total = len(img_directories), desc = \"Writing phase contrast FOV {} to disk\".format(FOV), leave = False))\n",
    "    for fluor_channel in fluor_channels:\n",
    "        img_directories = get_image_list(directory,FOV, fluor_channel)\n",
    "        images = []\n",
    "        for x in range(len(img_directories)):\n",
    "            images.append(io.imread(img_directories[x]))\n",
    "        sr = StackReg(StackReg.RIGID_BODY)\n",
    "        images = Parallel(n_jobs=-1)(  delayed(  sr.transform  )(image, trans_matrix) for image, trans_matrix in tqdm(zip(images, trans_matrices), total = len(images), desc = \"Transforming FL channel {} in FOV {}\".format(fluor_channel, FOV), leave = False))\n",
    "        for x in range(len(images)):\n",
    "            images[x] = images[x].astype(np.uint16)\n",
    "        Parallel(n_jobs=-1)(delayed(save_image)(directory, image) for directory, image in tqdm(zip(img_directories, images), total = len(images), desc = \"Writing FL channel {} images in FOV {} to disk\".format(fluor_channel, FOV), leave = False))\n",
    "\n",
    "\n",
    "def get_trenches(image, rotation, FOV, top_bottom = None, min_dist = 20, thres = 1.4, top_thres_multiplier = 1, bottom_thres_multiplier = 2):\n",
    "\n",
    "    test_image = img_as_uint(skimage.transform.rotate(image, rotation))\n",
    "    bin_image = test_image > threshold_li(test_image) * 1\n",
    "\n",
    "\n",
    "    x_mean_intensity = np.mean(bin_image, axis=0)\n",
    "    y_mean_intensity = np.mean(bin_image, axis=1)\n",
    "\n",
    "\n",
    "    top_threshold = np.mean(y_mean_intensity)/top_thres_multiplier\n",
    "    bottom_threshold = np.max(y_mean_intensity)/bottom_thres_multiplier\n",
    "    top_threshold_line = np.argmax(y_mean_intensity > top_threshold) - 10\n",
    "    bottom_threshold_line = np.argmax(y_mean_intensity > bottom_threshold)-10\n",
    "\n",
    "\n",
    "    indexes = peakutils.indexes(x_mean_intensity, thres=thres*np.mean(x_mean_intensity), min_dist=min_dist)\n",
    "\n",
    "\n",
    "    midpoints = (indexes[1:] + indexes[:-1]) / 2\n",
    "    #f, ax = plt.subplots(figsize=(10,5))\n",
    "    #plt.plot(x_mean_intensity)\n",
    "    #plt.plot(y_mean_intensity)\n",
    "    #plt.scatter(indexes, x_mean_intensity[indexes])\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(20,10))\n",
    "    plt.imshow(test_image)\n",
    "    plt.vlines(midpoints, ymin = 0, ymax = test_image.shape[0], color=\"r\")\n",
    "    plt.hlines(top_threshold_line, xmin = 0, xmax = test_image.shape[1], color=\"r\")\n",
    "    plt.hlines(bottom_threshold_line, xmin = 0, xmax = test_image.shape[1], color=\"r\")\n",
    "    plt.xlim(test_image.shape[1],0)\n",
    "    plt.ylim(test_image.shape[0],0)\n",
    "    plt.axis(\"off\")\n",
    "    if top_bottom == None:\n",
    "        plt.savefig(output_directory +  \"diagnostics/trench_finding/{}.jpeg\".format(FOV), bbox_inches=\"tight\")\n",
    "        plt.close(\"all\")\n",
    "    else:\n",
    "        plt.savefig(output_directory + \"diagnostics/trench_finding/{}_{}.jpeg\".format(FOV, top_bottom), bbox_inches=\"tight\")\n",
    "        plt.close(\"all\")\n",
    "\n",
    "    return top_threshold_line, bottom_threshold_line, midpoints\n",
    "\n",
    "directory = \"/home/georgeosh/lvm_super_cluster/Dropbox (Cambridge University)/DATA_Bakshi_PaulssonLab/ND2_extracted/40x_Ph2_testData_TIFFs/40x_Ph2_Test_1_5_TIFFs/\"\n",
    "output_directory = \"/home/georgeosh/lvm_super_cluster/Dropbox (Cambridge University)/DATA_Bakshi_PaulssonLab/ND2_extracted/40x_Ph2_testData_TIFFs/40x_Ph2_Test_1_5_TRENCHES/\"\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "phase_channel = \"BF\"\n",
    "other_channels = [\"RFP\"]\n",
    "\n",
    "make_diagnostic_directories(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOVs = get_FOVs(directory, \"BF\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:15<00:00,  1.59it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.52it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.39it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.55it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.37it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.64it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:20<00:00,  1.20it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.41it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.32it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.42it/s]\n",
      "100%|██████████| 25/25 [00:20<00:00,  1.23it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.38it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.39it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.44it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.39it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.35it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.27it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.40it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.26it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.38it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.34it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:20<00:00,  1.24it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.36it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.44it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.49it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.42it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.54it/s]\n",
      "100%|██████████| 25/25 [00:20<00:00,  1.19it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:21<00:00,  1.16it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.29it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.36it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.47it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.38it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.33it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.42it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.36it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.44it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.37it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.55it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.52it/s]\n",
      "100%|██████████| 25/25 [00:18<00:00,  1.38it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.39it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.52it/s]\n",
      "100%|██████████| 25/25 [00:14<00:00,  1.74it/s]\n",
      "100%|██████████| 25/25 [00:14<00:00,  1.69it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.63it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.50it/s]\n",
      "100%|██████████| 25/25 [00:19<00:00,  1.30it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.60it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.45it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.60it/s]\n",
      "100%|██████████| 25/25 [00:14<00:00,  1.69it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.59it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.57it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.53it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.45it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.45it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.51it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.56it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.41it/s]\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.60it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.44it/s]\n",
      "100%|██████████| 25/25 [00:16<00:00,  1.56it/s]\n",
      "100%|██████████| 25/25 [00:17<00:00,  1.40it/s]\n",
      "100%|██████████| 25/25 [00:13<00:00,  1.84it/s]\n",
      "Writing FL channel RFP images in FOV xy079 to disk:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "## This is destructive! Avoid running it more than once! Please re-extract the TIFFs from the ND2 file before proceeding if you accidentally run this twice. \n",
    "for FOV in FOVs:\n",
    "    register_transform_save_FOV(directory, FOV, \"BF\", [\"RFP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "double_mm = 1\n",
    "FOVs = get_FOVs(directory, \"BF\", 3)\n",
    "a = 0\n",
    "for FOV in FOVs:\n",
    "    initial_image = get_image_list(directory,FOV, \"BF\")[0]\n",
    "    image = io.imread(initial_image)\n",
    "    if a == 0:\n",
    "        rotation = get_orientation(image, debug = False)\n",
    "    fixed_image = fix_orientation(image, rotation)\n",
    "    fixed_image = img_as_uint(fixed_image)\n",
    "    cv2.imwrite(output_directory + \"diagnostics/rotations/{}.tif\".format(FOV), fixed_image, [cv2.IMWRITE_TIFF_COMPRESSION, 1])\n",
    "    if double_mm == 1:\n",
    "        top_half, bottom_half = get_img_half(image,\"top\"), get_img_half(image,\"bottom\")\n",
    "        bottom_half = img_as_uint(skimage.transform.rotate(bottom_half, 180))\n",
    "        cv2.imwrite(output_directory + \"diagnostics/top_split/{}.tif\".format(FOV), top_half, [cv2.IMWRITE_TIFF_COMPRESSION, 1])\n",
    "        cv2.imwrite(output_directory + \"diagnostics/bottom_split/{}.tif\".format(FOV), bottom_half, [cv2.IMWRITE_TIFF_COMPRESSION, 1])\n",
    "    a +=1\n",
    "#fixed_image = fix_orientation(all_images[0], rotation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = 0\n",
    "double_mm = 1\n",
    "FOVs = get_FOVs(directory, \"BF\", 3)\n",
    "a = 0\n",
    "trench_positions = {}\n",
    "for FOV in FOVs:\n",
    "    initial_image = get_image_list(directory,FOV, \"BF\")[0]\n",
    "    image = io.imread(initial_image)\n",
    "    if double_mm == 1:\n",
    "        top_half, bottom_half = get_img_half(image,\"top\"), get_img_half(image,\"bottom\")\n",
    "        bottom_half = img_as_uint(skimage.transform.rotate(bottom_half, 180))\n",
    "        trench_positions[\"{}_top\".format(FOV)] =  get_trenches(top_half, rotation, FOV, \"top\")\n",
    "        trench_positions[\"{}_bottom\".format(FOV)] = get_trenches(bottom_half, rotation, FOV, \"bottom\")\n",
    "    elif double_mm == 0:\n",
    "        trench_positions[\"{}\".format(FOV)] = get_trenches(image, rotation, FOV, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_FOVs = list(trench_positions.keys())\n",
    "try:\n",
    "    os.mkdir(output_directory + \"trenches/\")\n",
    "except:\n",
    "    pass\n",
    "for split_FOV in split_FOVs:\n",
    "    try:\n",
    "        os.mkdir(output_directory + \"trenches/\" + split_FOV)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(output_directory + \"trenches/\" + split_FOV + \"/\" + phase_channel)\n",
    "    except:\n",
    "        pass\n",
    "    for x in range(len(trench_positions[split_FOV][2])):\n",
    "        try:\n",
    "            os.mkdir(output_directory + \"trenches/\" + split_FOV + \"/\" + phase_channel + \"/\" + \"trench_{}\".format(str(x).zfill(2)))\n",
    "        except:\n",
    "            pass\n",
    "    for channel in other_channels:\n",
    "        try:\n",
    "            os.mkdir(output_directory + \"trenches/\" + split_FOV + \"/\" + channel)\n",
    "        except:\n",
    "            pass\n",
    "        for x in range(len(trench_positions[split_FOV][2])):\n",
    "            try:\n",
    "                os.mkdir(output_directory + \"trenches/\" + split_FOV + \"/\" + channel + \"/\" + \"trench_{}\".format(str(x).zfill(2)))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_trenches(FOV):\n",
    "    FOV_timepoint_images = get_image_list(directory,FOV, phase_channel)\n",
    "    for t in range(len(FOV_timepoint_images)):\n",
    "        timepoint = re.findall(\"T(\\d+)\", FOV_timepoint_images[t])[0]\n",
    "        image_dir = [image for image in FOV_timepoint_images if timepoint in image][0]\n",
    "        image = io.imread(image_dir)\n",
    "        top_half, bottom_half = get_img_half(image,\"top\"), get_img_half(image,\"bottom\")\n",
    "        bottom_half = img_as_uint(skimage.transform.rotate(bottom_half, 180))\n",
    "        ## Do the top split of the FOV first\n",
    "        top_threshold_line = trench_positions[\"{}_top\".format(FOV)][0]\n",
    "        bottom_threshold_line = trench_positions[\"{}_top\".format(FOV)][1]\n",
    "        midpoints = trench_positions[\"{}_top\".format(FOV)][2]\n",
    "        for y in range(len(midpoints)-1):\n",
    "            save_dir = output_directory + \"trenches/\" + FOV + \"_top/\" + phase_channel + \"/\" + \"trench_{}\".format(str(y).zfill(2)) + \"/T{}\".format(timepoint) + \".png\"\n",
    "            cropped_top = top_half[top_threshold_line:bottom_threshold_line,int(midpoints[y]):int(midpoints[y+1])]\n",
    "            imageio.imwrite(save_dir,cropped_top)\n",
    "        ## Do the bottom split of the FOV next\n",
    "        top_threshold_line = trench_positions[\"{}_bottom\".format(FOV)][0]\n",
    "        bottom_threshold_line = trench_positions[\"{}_bottom\".format(FOV)][1]\n",
    "        midpoints = trench_positions[\"{}_bottom\".format(FOV)][2]\n",
    "        for y in range(len(midpoints)-1):\n",
    "            save_dir = output_directory + \"trenches/\" + FOV + \"_bottom/\" + phase_channel + \"/\" + \"trench_{}\".format(str(y).zfill(2)) + \"/T{}\".format(timepoint) + \".png\"\n",
    "            cropped_top = bottom_half[top_threshold_line:bottom_threshold_line,int(midpoints[y]):int(midpoints[y+1])]\n",
    "            imageio.imwrite(save_dir,cropped_top)\n",
    "    for channel in other_channels:\n",
    "        FOV_timepoint_images = get_image_list(directory,FOV, channel)\n",
    "        for t in range(len(FOV_timepoint_images)):\n",
    "            timepoint = re.findall(\"T(\\d+)\", FOV_timepoint_images[t])[0]\n",
    "            image_dir = [image for image in FOV_timepoint_images if timepoint in image][0]\n",
    "            image = io.imread(image_dir)\n",
    "            top_half, bottom_half = get_img_half(image,\"top\"), get_img_half(image,\"bottom\")\n",
    "            bottom_half = img_as_uint(skimage.transform.rotate(bottom_half, 180))\n",
    "            ## Do the top split of the FOV first\n",
    "            top_threshold_line = trench_positions[\"{}_top\".format(FOV)][0]\n",
    "            bottom_threshold_line = trench_positions[\"{}_top\".format(FOV)][1]\n",
    "            midpoints = trench_positions[\"{}_top\".format(FOV)][2]\n",
    "            for y in range(len(midpoints)-1):\n",
    "                save_dir = output_directory + \"trenches/\" + FOV + \"_top/\" + channel + \"/\" + \"trench_{}\".format(str(y).zfill(2)) + \"/T{}\".format(timepoint) + \".png\"\n",
    "                cropped_top = top_half[top_threshold_line:bottom_threshold_line,int(midpoints[y]):int(midpoints[y+1])]\n",
    "                imageio.imwrite(save_dir,cropped_top)\n",
    "            ## Do the bottom split of the FOV next\n",
    "            top_threshold_line = trench_positions[\"{}_bottom\".format(FOV)][0]\n",
    "            bottom_threshold_line = trench_positions[\"{}_bottom\".format(FOV)][1]\n",
    "            midpoints = trench_positions[\"{}_bottom\".format(FOV)][2]\n",
    "            for y in range(len(midpoints)-1):\n",
    "                save_dir = output_directory + \"trenches/\" + FOV + \"_bottom/\" + channel + \"/\" + \"trench_{}\".format(str(y).zfill(2)) + \"/T{}\".format(timepoint) + \".png\"\n",
    "                cropped_top = bottom_half[top_threshold_line:bottom_threshold_line,int(midpoints[y]):int(midpoints[y+1])]\n",
    "                imageio.imwrite(save_dir,cropped_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [04:16<00:00,  3.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(extract_and_save_trenches)(FOV) for FOV in tqdm(FOVs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(output_directory + \"kymographs/\")\n",
    "except:\n",
    "    pass\n",
    "for split_FOV in split_FOVs:\n",
    "    try:\n",
    "        os.mkdir(output_directory + \"kymographs/\" + split_FOV)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(output_directory + \"kymographs/\" + split_FOV + \"/\" + phase_channel)\n",
    "    except:\n",
    "        pass\n",
    "    for channel in other_channels:\n",
    "        try:\n",
    "            os.mkdir(output_directory + \"kymographs/\" + split_FOV + \"/\" + channel)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_kymographs(FOV):\n",
    "    trench_directory = output_directory + \"trenches/\" + FOV + \"/\" + phase_channel + \"/\"\n",
    "    trench_directories = []\n",
    "    _ = os.listdir(trench_directory)\n",
    "    for x in range(len(_)):\n",
    "        trench_directories.append(trench_directory + _[x] + \"/\")\n",
    "    trench_directories.sort()\n",
    "    for z in range(len(trench_directories)):\n",
    "        trench_image_dirs = []\n",
    "        _ = os.listdir(trench_directories[z])\n",
    "        if len(_) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            for x in range(len(_)):\n",
    "                trench_image_dirs.append(trench_directories[z] + _[x])\n",
    "            trench_image_dirs.sort()\n",
    "\n",
    "            trench_image_arrays = []\n",
    "            for x in range(len(trench_image_dirs)):\n",
    "                trench_image_arrays.append(io.imread(trench_image_dirs[x]))\n",
    "            kymograph = np.concatenate(trench_image_arrays,axis=1)\n",
    "            trench_ID = re.findall(\"trench_(\\d+)\", trench_image_dirs[0])[0]\n",
    "            save_dir = output_directory + \"kymographs/\" + FOV + \"/\" + phase_channel + \"/trench_{}.png\".format(trench_ID)\n",
    "            imageio.imwrite(save_dir,kymograph)\n",
    "            \n",
    "    for channel in other_channels:\n",
    "        trench_directory = output_directory + \"trenches/\" + FOV + \"/\" + channel + \"/\"\n",
    "        trench_directories = []\n",
    "        _ = os.listdir(trench_directory)\n",
    "        for x in range(len(_)):\n",
    "            trench_directories.append(trench_directory + _[x] + \"/\")\n",
    "        trench_directories.sort()\n",
    "        for z in range(len(trench_directories)):\n",
    "            trench_image_dirs = []\n",
    "            _ = os.listdir(trench_directories[z])\n",
    "            if len(_) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                for x in range(len(_)):\n",
    "                    trench_image_dirs.append(trench_directories[z] + _[x])\n",
    "                trench_image_dirs.sort()\n",
    "\n",
    "                trench_image_arrays = []\n",
    "                for x in range(len(trench_image_dirs)):\n",
    "                    trench_image_arrays.append(io.imread(trench_image_dirs[x]))\n",
    "                kymograph = np.concatenate(trench_image_arrays,axis=1)\n",
    "                trench_ID = re.findall(\"trench_(\\d+)\", trench_image_dirs[0])[0]\n",
    "                save_dir = output_directory + \"kymographs/\" + FOV + \"/\" + channel + \"/trench_{}.png\".format(trench_ID)\n",
    "                imageio.imwrite(save_dir,kymograph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/160 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 8/160 [00:00<00:03, 50.48it/s]\u001b[A\n",
      " 10%|█         | 16/160 [00:09<00:50,  2.87it/s]\u001b[A\n",
      " 15%|█▌        | 24/160 [00:18<01:19,  1.72it/s]\u001b[A\n",
      " 20%|██        | 32/160 [00:28<01:39,  1.28it/s]\u001b[A\n",
      " 25%|██▌       | 40/160 [00:36<01:43,  1.16it/s]\u001b[A\n",
      " 30%|███       | 48/160 [00:45<01:45,  1.06it/s]\u001b[A\n",
      " 35%|███▌      | 56/160 [00:53<01:39,  1.04it/s]\u001b[A\n",
      " 40%|████      | 64/160 [01:03<01:39,  1.04s/it]\u001b[A\n",
      " 45%|████▌     | 72/160 [01:16<01:48,  1.23s/it]\u001b[A\n",
      " 50%|█████     | 80/160 [01:25<01:35,  1.19s/it]\u001b[A\n",
      " 55%|█████▌    | 88/160 [01:35<01:27,  1.21s/it]\u001b[A\n",
      " 60%|██████    | 96/160 [01:45<01:17,  1.21s/it]\u001b[A\n",
      " 65%|██████▌   | 104/160 [02:02<01:24,  1.51s/it]\u001b[A\n",
      " 70%|███████   | 112/160 [02:15<01:12,  1.52s/it]\u001b[A\n",
      " 75%|███████▌  | 120/160 [02:28<01:02,  1.57s/it]\u001b[A\n",
      " 80%|████████  | 128/160 [02:40<00:49,  1.55s/it]\u001b[A\n",
      " 85%|████████▌ | 136/160 [02:54<00:38,  1.60s/it]\u001b[A\n",
      " 90%|█████████ | 144/160 [03:04<00:23,  1.49s/it]\u001b[A\n",
      " 95%|█████████▌| 152/160 [03:14<00:11,  1.41s/it]\u001b[A\n",
      "100%|██████████| 160/160 [03:27<00:00,  1.30s/it]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(n_jobs=-1)(delayed(extract_and_save_kymographs)(FOV) for FOV in tqdm(split_FOVs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bita170c7cfa97747b189cda618a9652261"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
